# 常见的各种分布函数



## $0-1$分布



| $X=x_k$ | $1$  | $0$   |
| ------- | ---- | ----- |
| $p_k$   | $p$  | $1-p$ |



这种服从$0-1$分布的试验叫做**贝努利试验**

$n$重贝努利试验概型研究$n$次试验中事件出现$k$次的概率，记为$P_n(k)$



其**期望**为：$E(x) = p$

其**方差**为：$D(x)=p(1-p)$



## 二项分布

$P_n(k)=P(X=k)=C_n^kp^k(1-p)^{n-k}$

就记为$X$是服从参数为$n$，$p$的二项分布，记为：

$X \sim B(n,p)$



其**期望**为：$E(x)=np$

其**方差**为：$D(x) = np(1-p)$



---

当$n$较大，$p$较小，而$np=\lambda$，则可以近似认为：

$C_n^k(1-p)^{n-k}p^{k} \approx e^{-\lambda}\frac{\lambda ^k}{k!}$





## Poisson 分布

$P(X=k)=e^{-\lambda}\frac{\lambda^k}{k!}$

就记为$X$是服从参数为$\lambda$的Poisson分布，记作$X \sim \pi(\lambda)$或者$X \sim P(\lambda)$



其**期望**为：$E(x) = \lambda$



## 均匀分布

### 一维

**密度函数**为：

$f(x) = \begin{cases} \frac{1}{b-a} \ a < x < b \\ 0 \ 其他 \end{cases}$

**记作**：

$X \sim U(a, b)$



其**期望**$E$为：$\frac{a + b}{2}$

其**方差**$D$为：$\frac{(b-a)^2}{12}$

## 二维

**密度函数**为：

$f(x,y)=\begin{cases}\frac{1}{A} \ (x,y) \in G \\ 0 \ 其他\end{cases}$

**记作**：

$(X, Y) \sim U(G)$

 	

## 指数分布

**密度函数**为：

$f(x) = \begin{cases} \lambda e ^{- \lambda x}\ (x > 0) \\ 0 \ 其他 \end{cases}$

**记作**：

$X \sim E(\lambda)$

> 分布函数为：$F(x) = \begin{cases} 0 \ x < 0 \\ 1 - e^{- \lambda x} \ (x \ge 0)\end{cases}$



## 正态分布

### 一维

**密度函数**为：

$f(x)=\frac{1}{\sigma \sqrt{2 \pi}} e ^{-\frac{(x-\mu)^2}{2 \sigma ^ 2}} \ \ (-\infin < x < \infin)$

**记作**：

$X \sim N(\mu, \sigma^2)$



> 欧拉-泊松积分：$\int_{-\infin}^{+\infin}e^{-x^2}dx=\sqrt{\pi}$



其**期望**为：$E(x) = \mu$



> 对于一般的正态分布$X \sim N(\mu, \sigma^{2}) = \Phi(\frac{x-\mu}{\sigma})$，（其中，$\Phi$指的是标准正态分布函数）



### 二维

**密度函数**为：

$f(x,y)=\frac{1}{2 \pi \sigma_1 \sigma_2 \sqrt{1 - \rho ^ 2}} e^{-\frac{1}{2(1 - \rho^2)}[(\frac{x-\mu_1}{\mu_1})^2-2\rho\frac{x-\mu_1}{\sigma_1}\frac{y-\mu_2}{\sigma_2}+(\frac{y-\mu_2}{\sigma_2})^2]}$

> \* *this formula is not very important*

则称$(X,Y)$服从参数为$\mu_1$，$\mu_2$，$\sigma_1$，$\sigma_2$，$\rho$的二维正态分布，记为：

$(X,Y) \sim N(\mu_1, \sigma_1^2 ; \mu_2, \sigma_2^2, \rho)$



### $n$维

**密度函数**为：

$f(x_1, x_2, \dots, x_n) = \frac{1}{(2 \pi)^{\frac{n}{2}}\det(C)}e^{[-\frac{1}{2}(X - \mu)^{T}C^{-1}(X-\mu)]}$

> \* *this formula is not very important*

$C=(c_{ij})_{n \times n}$是对称正定矩阵



## 大$U$分布

对于$X \sim N(\mu, \sigma^2 )$，$X_1, X_2, X_3 \dots$是$X$的一个样本

那么$\sum{a_ix_i + b} \sim N(\mu \sum{a_i + b},\sigma^2\sum{a_i^2})$ 



特别地，有：



$U = \frac{\overline{X} - \mu}{\frac{\sigma}{\sqrt{n}}}\sim N(0, 1)$



## $\chi^2(x)$卡方分布

**一大坨正态平方相加分布**

对于$X_1,X_2,\dots,X_n$独立并且都服从正态分布$N(0, 1)$，那么定义

$\sum x_i^2 \sim \chi^2(n)$（n称为自由度）



其**期望**为：$E(\chi^2(n))=n$

其**方差**为：$D(\chi^2(n))=2n$



---

**非常非常非常重要的性质[**

如果$X_1, X_2, X_3 \dots X_n$相互独立，并且都服从$N(\mu, \sigma^2)$

那么

- $\overline{X}$和$S^2$相互独立
- $\frac{(n-1)}{\sigma^2}S^2 \sim \chi^2(n-1)$



## $t$分布

对于$X \sim N(0, 1)$，$Y \sim \chi^2(n)$，如果$X$，$Y$相互独立，令$T = \frac{X}{\sqrt{\frac{Y}{n}}}$

那么$T$所服从的分布称为自由度为$n$的$t$分布，记为：

$T \sim t(n)$



---

设$X_1, X_2, \dots X_n$相互独立，并且都服从$N(\mu, \sigma^2)$

那么$\frac{\overline{X}-\mu}{\frac{S}{\sqrt{n}}}=\frac{(\overline{x}-\mu)\sqrt{n}}{S}\sim t(n-1)$



## $F$分布

设$X \sim \chi^2(n) \ Y \sim \chi^2(m)$，并且$X$，$Y$相互独立，那么令$F=\frac{\frac{X}{n}}{\frac{Y}{m}}$

记为$F \sim F(n, m)$（$n$是第一自由度，$m$是第二自由度）



# 分位点

## 正态分布的分位点

如果$X \sim N(0, 1)， 0 < \alpha < 1$，那么把满足$P(X \le z_\alpha) = \alpha$的点$z_\alpha$称为$X$的$\alpha$分位点



**常用**：$z_{0.95}=1.645$	$z_{0.975}=1.96$	$z_{0.5}=0$	$z_0=-\infin$	$z_1 = +\infin$



## $\chi^2(n)$卡方分布的分位点

满足：$F_{\chi^2}(\chi^2_\alpha(n))=P\{\chi^2 \le \chi^2_\alpha(n)\}=\int_{-\infin}^{\chi^2_\alpha(n)}f(y) dy = \alpha$



当$n > 45$的时候，可以用式子：

$\chi^2_\alpha(n)\approx\frac{1}{2}(z_\alpha+\sqrt{2n-1})^2$

来求得$\chi^2_\alpha(n)$的近似值



# 随机变量之间的函数关系

$\max\{a, b\} = \frac{a+b}{2}+\frac{|a-b|}{2}$

$\min\{a,b\}=\frac{a+b}{2}-\frac{a-b}{2}$



如果$z = \max\{X, Y\}$，那么

$F_z(z)=P(\max\{x, y\} \le z) = P\{x \le z, y \le z \} = F(z,z)$

如果$X$和$Y$相互独立，还能继续写成$=F_X(z)F_Y(z)$



如果$z=\min\{X, Y\}$，那么

$F_z(z)=P(\min\{x, y\} < z) = 1 - P(\min\{x, y\} > z) = 1 - P(x > z, y > z) = 1 - P(z < x < +\infin, z < y < +\infin)=F_X(z)+F_Y(z)-F(z,z)$

如果$X$和$Y$相互独立，还能写成$=1-P(x>z)P(y>z)=1-(1-F_X(z))(1-F_Y(z))$



推广到$n$个独立的随机变量，$M=\max() \ N=\min()$

则$F_M(u)=(F(u))^n$	$F_N(v)=1-(1-F(v))^n$



# 重要的数学特征及其性质



## 期望

$E(X^k)$ ：$X$的$k$阶原点距

$E(|x|^k)$：$X$的$k$阶绝对原点距

$E((X-E(X))^k)$：$X$的$k$阶中心距

$E((X-E(X))^2)=D(X)$：方差



$E(C)=C$ **常数的期望是常数本身**

$E(aX) = aE(X)$ **常数倍数的期望获得常数倍数**

$E(X + Y) = E(X) + E(Y)$ **和之期望等于期望之和**

$E(\sum{a_i x_i} + C) = \sum{a_iE(x_i)}+C$ **混用推广**



如果$XY$相互独立，那么$E(XY)=E(X)E(Y)$，**积之期望等于期望之积**

如果有常数$a$使得$P(x \ge a) = 1$，那么$E(X) \ge a$ **期望一定大于下限**

如果有常数$b$使得$P(x \le b) = 1$，那么$E(X) \le b$ **期望一定小于上限**



## 方差

$D(C) = 0$ **常数无方差**

$D(aX + b) = a^2D(X)$**相加常数与方差无关，相乘倍数平方贡献**

$D(X \pm Y) = D(X) + D(Y) \pm 2E((X - E(X)) (Y - E(Y)))$ **和差之方差等于方差之和差，加/减上二倍协方差**

$D(XY) = E((XY)^2) - [E(XY)]^2$ **积之方差等于积平方之期望减积期望之平方**



> 常用的特殊形式：$D(X) = E(X^2) - E^2(X)$，方差等于平方的期望减期望的平方



## 协方差

记$E((X-E(X))(Y-E(Y)))$为协方差，记为$cov(X,Y)$

$(X,Y)$的协方差矩阵记为：

$\begin{bmatrix}D(X) & cov(X, Y) \\ cov(X,Y) & D(Y)\end{bmatrix}$



## 相关系数

$\rho_{xy}=\frac{cov(X, Y)}{\sqrt{D(X)}\sqrt{D(Y)}}$



如果$\rho_{xy} = 0$，我们就说$XY$不相关/不线性相关 **注意，不是相互独立**

如果$|\rho_{xy}| = 1$，我们就说$XY$存在某种线性相关关系



对于一般的随机变量：

$X$与$Y$相互独立$\Rightarrow E(XY)=E(X)E(Y), cov(X,Y)=0, \rho=0$

反之不能推导



**柯西—许瓦兹** 不等式：
$|E(XY)| \le \sqrt{E(x^2)} \sqrt{E(y^2)}$



# 大数定律和中心极限定理



## 概率不等式

---

### 马尔可夫不等式

随机变量$X$的$k$阶绝对原点矩存在，那么$\forall \varepsilon > 0, P\{|X| \ge \varepsilon \} \le \frac{E|X|^k}{\varepsilon^k}$



### 切比雪夫不等式

设随机变量$X$的数学期望和方差存在，那么$\forall \varepsilon > 0, P(|X -E(X)| \ge \varepsilon) \le \frac{D(X)}{\varepsilon ^2}$



---



## 大数定律

---

### 切比雪夫大数定律

如果随机变量序列$x_1, x_2, x_3, \dots x_n \dots$相互独立，每个$x_i$都有有限的方差和公共的上界，那么

$\forall \varepsilon > 0$ 有

$\lim_{n \rightarrow \infin}P{|\frac{1}{n}\sum_{i=1}^n{X_i}-\frac{1}{n}\sum_{i=1}^{n}EX_i| < \varepsilon} = 1$



> 就是平均值和期望之和一定会越来越贴近



### 伯努利大数定律

如果$n_A$是$n$次独立重复试验当中$A$发生的次数，$p$是每次试验当中$A$发生的概率，那么

$\forall \varepsilon > 0$有：

$\lim_{n \rightarrow \infin} P(|\frac{n_A}{n} - p| < \varepsilon) = 1$



> 频率和概率一定会越来越贴近



### 辛钦大数定律

设$x_1, x_2, \dots x_n$相互独立同分布，且具有相同的数学期望$\mu$，那么

$\forall \varepsilon > 0$有

$\lim_{n \rightarrow \infin}P(|\frac{1}{n}\sum_{i=1}^{n}x_i-\mu|<\varepsilon)=1$

> 平均值和期望一定会越来越贴近



**注意它不要求方差存在**

---



## 中心极限定理

一个独立的随机变量序列：$x_1, x_2, \dots x_n $，如果它存在期望和方差，令

$z_n = \frac{\sum_{i=1}^nX_i-\sum_{i=1}^{n}EX_i}{\sqrt{\sum_{i=1}^{n}DX_i}}$

如果这个$z_n$，对于$\forall x \in R$有

$\lim_{n \rightarrow \infin} P\{z_n \le x\} = \frac{1}{\sqrt{2 \pi}}\int_{-\infin}^{x}e^{-\frac{t^2}{2}}dt$

> 就是随机变量之和标准化过后，极限是正态分布

那么就说$\{X_n\}$服从中心极限定理



其中，$\frac{X-EX}{\sqrt{D(X)}}=X^*$，$X^*$称为$X$的标准化



### 独立同分布的中心极限定理

---

如果随机变量序列$X_1, X_2 \dots X_n$相互独立，并且服从同一分布，方差和期望存在



那么：
对于$\forall x \in R$

有 $\lim_{n \rightarrow \infin} P(\frac{\sum x - n\mu}{\sqrt{n}\sigma})=\frac{1}{\sqrt{2 \pi}}\int_{-\infin}^x e^{-\frac{t^2}{2}}dt$

> 也就是说，一些独立同分布随机变量序列，有方差和期望的前提下，标准化后不断累积，最终会服从正态分布
>
> 这也是为什么正态分布如此常见



### 德莫佛-拉普拉斯定理

设$\mu_n$是$n$次独立重复试验当中$A$发生的次数，$p$是每次$A$发生的概率，那么对于任何的区间$[a, b]$：

$\lim_{n \rightarrow \infin}P(a < \frac{\mu_n-np}{\sqrt{np(1-p)}} < b) = \int_a^b\frac{1}{2 \pi} e^{-\frac{r^2}{2}}dt = \Phi (b) - \Phi(a)$

> 也就是说，任何一个独立重复试验，进行足够多次后进行*类似*标准化的操作后，是正态分布形式



# 参数估计

理论依据：**大数定律** （大数定律告诉我们，样本足够多，会无限贴近于理论值）

## 矩估计

先找总体矩和参数之间的关系

$A_l = \frac{1}{n}\sum x_i^l = \mu^l$

然后列方程：

$\begin{cases}\mu_1(\theta_1,\dots,\theta_k) = A_1 \\ \mu_2(\theta_1,\dots,\theta_k)=A_2 \\ \dots\\ \mu_k(\theta_1, \dots \theta_k) = A_k\end{cases}$

解出$\hat{\theta_l}=\hat{\theta_l}(\theta_1, \dots, \theta_k)$，直接作为$\theta_l$的估计值，这种估计值就是**矩估计值**



## 极大似然估计

> 一次试验就出现的事件说明很大概率



考虑理论值$(X_1,X_2,\dots,X_n)$落在实际样本值$(x_1, x_2, \dots, x_n)$的领域的概率为：

$P(|X_i - x_i| \le \frac{\triangle x_i}{2}) \approx \Pi_{i = 1}^nf(x_i, \theta) \ \Pi_{i=1}^n \triangle \theta_i$

如果让其最大，很明显我们要让$\Pi_{i=1}^nf(x_i, \theta)$最大

我们把**使其值最大的参数组作为参数的估计值**



定义似然函数为：$L(x_1, x_2 \dots \theta_1, \theta_2\dots) = \Pi_{i = 1} ^{n} f(x_i, \theta_1, \theta_2, \dots)$



求法：使用**偏导**

$\frac{\part}{\part\theta_r}L(x_1,x_2\dots,\theta_1, \theta_2\dots)=0$的一系列方程作为 **似然方程组**， 解出的$\theta$组合就作为所有参数的估计值



## 点估计的评价标准

- 无偏性 $E(\hat{\theta}) = \theta$
- 有效性 （方差尽量小）
- 一致性 （$\lim_{n \rightarrow \infin}P(|\hat \theta - \theta| > \varepsilon = 0)$



## 置信区间 （很重要，而且贼~~TM~~难记）

-  $\sigma^2$已知，$\mu$的置信区间：

  ​	$(\overline{X} - z_{1- \frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}, \overline{X} + z_{1-\frac{a}{2}}\frac{\sigma}{\sqrt{n}})$ （置信度为$1 - \alpha$）

- $\sigma^2$未知，$\mu$的置信区间：

  ​	$(\overline{X} - t_{1 - \frac{\alpha}{2}}(n-1)\frac{S}{\sqrt{n}}, \overline{X} + t_{1 - \frac{\alpha}{2}}(n - 1)\frac{S}{\sqrt{n}})$ （置信度为$1-\alpha$）

- $\mu$未知，$\sigma^2$的置信区间：

  > \* org: $P(\chi^2_{\frac{\alpha}{2}}(n - 1) < \frac{(n-1)S^2}{\sigma^2}<\chi^2_{1-\frac{\alpha}{2}}(n-1))$

  $(\frac{(n-1)S^2}{\chi_{1-\frac{\alpha}{2}}^2(n-1)},\frac{(n-1)S^2}{\chi_{\frac{\alpha}{2}}^2(n-1)})$ 

  > 注意，网络上查询到的一些卡方分布的分位点表定义和课内有所区别



## 假设检验

> 省流：观测值和置信区间进行比较，如果发生了小概率事件，就拒绝某参数确定赋值的命题



# 随机过程

**均值函数**$\mu_x(t)$：$\int_{-\infin}^{+\infin}xf_1(x;t)dx$

**均方值函数**$\Psi^2_x(t)$：$\int_{-\infin}^{+\infin}x^2f_1(x;t)dx$

**方差函数**$\sigma^2_x(t)$：$D[X(t)] = E[X(t) - EX(t)]^2=E(X^2(t))-\mu_x^2(t)$

**自相关函数**$R_x(t_1,t_2)$：$E[X(t_1)X(t_2)]$

**协方差函数**：$C_x(t_1, t_2)$：$E\{[X(t_1)-EX(t_1)][X(t_2)-EX(t_2)]\}$



# 平稳过程

> 其实就是分布性质和时间没有关联

## 严平稳过程：

$F(x_1, x_2 \dots ; t_1, t_2 \dots) = F(x_1, x_2 \dots ; t_1 + \varepsilon, t_2 + \varepsilon , \dots)$

严平稳过程下，**二维分布函数**：$F_2(x_1, x_2;t_1,t_2)$只依赖于间距$\tau=t_2-t_1$，和$t_1, t_2$的绝对大小无关联



对于一个严平稳过程$X(t)$，如果二阶矩存在，那么

- $E[X(t)]=\mu_x$	$E[X^2(t)]=\Psi^2_x$	$D[X(t)]=\sigma^2_x$

​	**均为常数，与时间$t$无关**



- $E[X(t)X(t+\tau)]=R_x(\tau)$

  $E\{[X(t)-EX(t)][X(t+\tau)-EX(t+\tau)]\} = C_x(\tau)$ （这个记号的意思是只与差值$\tau$有关，与绝对时间位置无关）



## 广义平稳过程

对于随机过程$X(t),\forall t \in T$有

- $E(X^2(t))$存在且有限
- $E(X(t))=\mu_x$是常数
- $E(X(t)X(t+\tau))=R_X(\tau)$仅与$\tau$有关



那么就说$X(t)$是一个**广义（宽）平稳过程**

> 其实就是严平稳过程的推广

具有性质：

- $E(X^2(\tau)) = \Psi_x^2=R_x(0)$ 是常数
- $D(X(t))=\Psi_X^2 - \mu_X^2 = \sigma_X^2$是常数

……



## 正态平稳过程

如果正态过程$X(t)$同时还是广义平稳过程，就说$X(t)$是一个**正态平稳过程**

对于正态过程，那么它**同时是，或者同时不是**严平稳过程和广义平稳过程



## 遍历过程~~foreach~~

>  关于时间的稳定不变性



**时间均值**：$\overline{X(t)}=\lim_{l \rightarrow + \infin}\frac{1}{2l}\int_{-l}^{l}X(t)dt$ 

> 对于时间只能为非负的，为$\lim_{l \rightarrow +\infin}\frac{1}{l}\int_{0}^lX(t)dt$



**时间相关函数**：$\overline{X(t)X(t + \tau)} = \lim_{l \rightarrow +\infin}\int_0^lX(e,t)X(e,t+\tau)dt$

> 描述了和时间的相关性



#### 各态遍历性 （！！重要）

对于一个平稳过程$X(t)$

- 如果$P\{\overline{X(t)}=E[X(t)]=\mu_X\}=1$，那么就说$X(t)$的均值有**各态遍历性**
- 如果$P\{\overline{X(t)X(t+\tau)}=E(X(t)X(t+\tau))=R_X(\tau)\}=1$ 那么就说过程$X(t)$的自相关函数有**各态遍历性**
- 如果上面两个条件**都是满足的**，那么就说$X(t)$是一个**遍历过程**，或者说这个随机平稳过程有**遍历性**



# 马尔可夫链

> *下一刻状态只与此时有关*



如果一个随机过程$\{X(t), t\in T\}$的状态空间$S$是一个**有限集或者可列集**，对于$\forall n \in N^*$，对于$T$内任何$n+1$个参数$t_1<t_2<\dots<t_{n+1}$和$S$内任意$n+1$个状态$j_1,j_2\dots j_{n+1}$，如果条件概率：


$$
P\{X(t_{n+1})=j_{n+1}|X(t_1)=j_1,X(t_2)=j_2\dots X(t_n) = j_n\} = P(X(t_{n+1})=j_{n+1}|X(t_n)=j_n)
$$

> 只与上一次有关



那么就说这个随机过程有**马尔可夫性**/**无后效性**

这个随机过程称为**马尔科夫链**



这个**条件概率**：$P\{X(t_{m+n})=j|X(t_m)=i\}=P_{ij}^{(n)}t_m$

是$X(t)$在时刻$t_m$由$i$经过$n$步到达$j$的**$n$步转移概率**，简称**转移概率**



### 齐次马尔科夫链

> *$n$步转移永远不变*



如果对于$\forall t_m,t_k (m \ne k)$有：
$$
P\{X(t_{m+1})=j|X(t_m)=i\}=P_{ij}(t_m)=P\{X(t_{k+1})=j|X(t_k)=i\}=P_{ij}(t_k)=P_{ij}
$$

---



**显然，如果$X(t)$的状态空间有限可列，并且独立，那么它一定是一个齐次马尔科夫链**



### 切普曼-柯尔莫哥洛夫方程

> *类似弗洛伊德算法*

- 如果$\{X(t), t=t_0, t_1, t_2 \dots\}$是一个马尔可夫链，那么

$$
P_{ij}^{(n+l)}(t_m)=\sum_kP_{ik}^{(n)}(t_m)P_{kj}^{(l)}(t_{m+n})
$$

​	或者写成矩阵的形式：
$$
P^{(n+l)}(t_m)=P^{(n)}(t_m)P^{(l)}(t_{m+n})
$$
​	如果一直这个马尔科夫链还是 **齐次** 的，我们**可以忽略起始时间，只关心时间间隔**





---

## 有限维概率分布

**初始分布**：$P_j(t_0)=P\{X(t_0)=j\}\ j=0,1,2,\dots$



**一维概率分布**：

​	马尔科夫链在任何时刻$t_n$的一维概率分布
$$
P_j(t_n)=P\{X(t_n)=j\}
$$
​	称为**绝对概率**或者**瞬时概率**

​	这个概率完全由初始分布和$n$步转移概率来确定

​	

​	对于**一般的**马尔科夫链：
$$
P_j(t_n)=\sum_{i=0}^{+\infin}P_i(t_0)P_{ij}^{(n)}(t_0)
$$
​	我们**需要关心起始状态的时间**



​	而对于**齐次的**马尔科夫链
$$
P_j(t_n)=\sum_{i=0}^{+\infin}P_iP_{ij}^{(n)}
$$
​	（忽略起始时间）



​	**向量转移形式**：
$$
(P_0(t_n), P_1(t_n), \dots, P_j(t_n), \dots) = (P_0(t_0), P_1(t_0), \dots, P_j(t_0), \dots)P^{(n)}
$$


**定理**：对于一个**齐次马尔科夫链**$X(n)$，它对应状态空间$S=\{0,1,2,\dots\}$，那么对于$T$内任意$n$个非负整数$k_1<k_2<\dots<k_n$和$S$内任意$n$个状态，有：
$$
P\{X(k_1)=j, X(k_2)=j_2\dots,X(k_n)=j_n\}=\sum_{i=0}^{+\infin}P_i(0)P_{ij_1}^{k_1}P_{j_1j_2}^{(k_2 - k_1)}\dots P_{j_{n-1}j_n}^{(k_n-k_{n-1})}
$$


## 平稳分布

> *依附于齐次马氏链的分布*



对于一个齐次马氏链$X(t)$，一维概率分布$P_j(t_n)=P_j$（齐次的马氏链时间无关）

**如果**，存在一个概率分布$P_j'$，满足：$P_j' = \sum_{i=0}^{\infin}P_iP_{ij}$

那么就说$P_{j}'$是一个平稳分布，称$X(t)$有**平稳性**，是**平稳齐次马尔科夫链**

最直观的：
$$
(P_0, P_1, P_2, \dots) = (P_0,P_1,P_2,\dots)P
$$
